{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjxSpc/KTtlgS8zgXwc1p1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edermartelinho/Modelos_Linguagem_Neurais-LLM-/blob/main/LLM_Tkenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências"
      ],
      "metadata": {
        "id": "sZM5Ed8Qnad7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i21KJFjnNvu"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "from tabulate import tabulate\n",
        "from google.colab import widgets as cwidgets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interactive, widgets, interactive_output"
      ],
      "metadata": {
        "id": "vlcyEEQZoM4T"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Definições das Funções"
      ],
      "metadata": {
        "id": "J552xwhUoR3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = [5,9,34,62,93,208]\n",
        "\n",
        "# Formata a string para ter uma cor de fundo\n",
        "def colored(txt: str, idx: int):\n",
        "    color = COLORS[idx%len(COLORS)]\n",
        "    return f\"\\x1B[1m\\x1B[48;5;{color}m{txt}\\x1B[0m\""
      ],
      "metadata": {
        "id": "L69ym416oaUb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'AllanFrostin/analise-morfossintatica-ptbr'\n",
        "# Inicializando o tokenizador e modelo a serem usados\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"AllanFrostin/analise-morfossintatica-ptbr\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"AllanFrostin/analise-morfossintatica-ptbr\")"
      ],
      "metadata": {
        "id": "cyg7uJusog5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa uma string em tokens e imprime cada token com uma cor de fundo\n",
        "def print_colored_tokens(text: str):\n",
        "    # Realiza a tokenização\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Imprime os tokens com diferentes cores\n",
        "    print('\\x1B[1mDivisão do Texto\\x1B[0m:\\t', end='')\n",
        "    for idx, token in enumerate(tokens):\n",
        "        print(colored(token.replace(\"▁\", \" \"), idx), end='')\n",
        "\n",
        "    print('\\n\\x1B[1mTokens Ids\\x1B[0m:\\t\\t' + str(tokenizer(text)['input_ids'][:-1]))"
      ],
      "metadata": {
        "id": "liKRiqhwomkG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def print_input_embeddings(text, hidden_states):\n",
        "    #Tokeniza o texto\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Inicializa a lista de dados para a tabela de embeddings\n",
        "    # Adiciona os tokens como headers e prepara lista vazias para\n",
        "    # receberem os embeddings\n",
        "\n",
        "    embed_size = 150\n",
        "\n",
        "    fig, axs = plt.subplots(len(tokens), 1, figsize=(15,len(tokens)//1.2))\n",
        "    fig.patch.set_visible(False)\n",
        "    # Itera sobre os tokens e embeddings para preencher a tabela\n",
        "    for i, token in enumerate(tokens):\n",
        "        token_embedding = hidden_states[0][0][i+1, :embed_size].unsqueeze(0).tolist()\n",
        "        img = axs[i].imshow(token_embedding, cmap='Spectral', extent=[0,embed_size,0,embed_size//20])\n",
        "        axs[i].set_frame_on(False)\n",
        "        axs[i].set_xticks([])\n",
        "        axs[i].set_yticks([])\n",
        "        axs[i].set_ylabel(token, rotation=0, verticalalignment='center', horizontalalignment='right')\n",
        "\n",
        "\n",
        "    plt.colorbar(img, ax=axs)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AC7kLxWboyeg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Primeiramente vamos selecionar um texto para tradução, o qual será a entrada do modelo."
      ],
      "metadata": {
        "id": "iqqn6VOXo44j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Primeiramente vamos selecionar um texto para tradução, o qual será a entrada do modelo.\n",
        "Input = \"barco vira na praia\" # @param @type {type: \"string\"}"
      ],
      "metadata": {
        "id": "Klm7LltSo8T2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokens"
      ],
      "metadata": {
        "id": "YywLG_iwqjpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para que o transformer possa processar dados textuais, os mesmos devem ser transformados em vetores numéricos. Para isso, a entrada é dividida em tokens com base em um dicionário previamente definido.\n",
        "\n",
        "Os dicionários costumam ser únicos para cada modelo e as palavras ou sub-palavras presentes neles são escolhidas pela taxa de ocorrência das mesmas nos dados de treinamento. Os dicionários mapeiam cada token (palavra ou sub-palavra) para um índice (token id)."
      ],
      "metadata": {
        "id": "ORDADHncrXSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_colored_tokens(Input)"
      ],
      "metadata": {
        "id": "0pv3BHQHrfcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}